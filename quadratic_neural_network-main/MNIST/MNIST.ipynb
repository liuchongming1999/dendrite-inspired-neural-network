{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import model.simplenet as simplenet\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import imageio\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.linewidth'] = 2.5\n",
    "mpl.rcParams['legend.fontsize'] = 12\n",
    "mpl.rcParams['axes.labelsize'] = 12\n",
    "mpl.rcParams['axes.titlesize'] = 14\n",
    "mpl.rcParams['font.weight'] = 'bold'\n",
    "mpl.rcParams['font.size'] = 12\n",
    "mpl.rcParams['axes.labelweight'] = 'bold'\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "\n",
    "def change_weight(weight):\n",
    "    '''\n",
    "    Change the weight matrix in quadratic neural network.\n",
    "    '''\n",
    "    model_dict = model.state_dict()\n",
    "    model_dict['classifier.0.weight_a'] = weight\n",
    "    model.load_state_dict(model_dict)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def change_eigen(eigen):\n",
    "\n",
    "    model_dict = model.state_dict()\n",
    "    model_dict['classifier.0.eigen'] = eigen\n",
    "    model.load_state_dict(model_dict)\n",
    "    \n",
    "    return\n",
    "\n",
    "def eigen_decomposition(a, initial, remain_number = 40):\n",
    "    '''\n",
    "    Finding the low-dimensional sturcture for a weight matrix weight_a in quadratic \n",
    "    neural network. (Accuracy change with respect to the remaining eigens.)\n",
    "    '''\n",
    "    \n",
    "    weight_a_change = torch.zeros(10,784,784)\n",
    "    test_accuracy = torch.zeros(remain_number)\n",
    "    #out = torch.zeros(remain_number,10,10)\n",
    "    \n",
    "    for k in range(remain_number):\n",
    "        for i in range(10):\n",
    "            weight = (a-initial)[i,:,:]\n",
    "            u,s,v = torch.svd(weight)\n",
    "            s_1 = torch.zeros(784,784)\n",
    "            for j in range(k):\n",
    "                s_1[j,j] = s[j]\n",
    "            weight_a_change[i,:,:]  = torch.mm(torch.mm(u,s_1),v.t())\n",
    "    \n",
    "        change_weight(weight_a_change+initial)\n",
    "\n",
    "        model.eval()\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            for i, (input, target) in enumerate(valid_loader):\n",
    "                input, target = input, target.long()\n",
    "            # compute output\n",
    "                output = model(input)\n",
    "                #for digit in range(10):\n",
    "                 #   out[k,:,digit] = torch.sum(output[target==digit,:],dim=0)/torch.sum(target==digit)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                valid_total = target.size(0)\n",
    "                valid_correct = (predicted == target).sum().item()\n",
    "\n",
    "            \n",
    "            \n",
    "        prec = valid_correct / valid_total\n",
    "        print('Accuary on test images:{:.2f}%'.format(prec*100))\n",
    "        print('index of eigen:{}'.format(k))\n",
    "    \n",
    "        test_accuracy[k] = prec\n",
    "\n",
    "    return test_accuracy\n",
    "\n",
    "\n",
    "def eigen_decomposition_1(a, remain_number = 40):\n",
    "    '''\n",
    "    Finding the low-dimensional sturcture for a weight matrix weight_a in quadratic \n",
    "    neural network. (Accuracy change with respect to the remaining eigens.)\n",
    "    '''\n",
    "    \n",
    "    weight_a_change = torch.zeros(10,784,784)\n",
    "    test_accuracy = torch.zeros(remain_number)\n",
    "    #out = torch.zeros(remain_number,10,10)\n",
    "    \n",
    "    for k in range(remain_number):\n",
    "        for i in range(10):\n",
    "            weight = a[i,:,:]\n",
    "            u,s,v = torch.svd(weight)\n",
    "            s_1 = torch.zeros(784,784)\n",
    "            for j in range(k):\n",
    "                s_1[j,j] = s[j]\n",
    "            weight_a_change[i,:,:]  = torch.mm(torch.mm(u,s_1),v.t())\n",
    "    \n",
    "        change_weight(weight_a_change)\n",
    "\n",
    "        model.eval()\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(valid_loader):\n",
    "                input, target = input, target.long()\n",
    "            # compute output\n",
    "                output = model(input)\n",
    "                #for digit in range(10):\n",
    "                 #   out[k,:,digit] = torch.sum(output[target==digit,:],dim=0)/torch.sum(target==digit)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                valid_total = target.size(0)\n",
    "                valid_correct = (predicted == target).sum().item()\n",
    "\n",
    "            \n",
    "            \n",
    "        prec = valid_correct / valid_total\n",
    "        print('Accuary on test images:{:.2f}%'.format(prec*100))\n",
    "        print('index of eigen:{}'.format(k))\n",
    "    \n",
    "        test_accuracy[k] = prec\n",
    "        #change_weight(a)\n",
    "\n",
    "    return test_accuracy\n",
    "\n",
    "\n",
    "def generate_spike_trigger_average():\n",
    "    '''\n",
    "    Generate spike trigger average of MNIST dataset\n",
    "    (approximated by the mean of each digits in the dataset.)\n",
    "    '''\n",
    "    \n",
    "    train_dataset = torchvision.datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=60000, shuffle=True)\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        a = 0\n",
    "    input = input.reshape(60000,784)\n",
    "\n",
    "    spike_trigger_average = torch.zeros(10,784)\n",
    "\n",
    "    for j in range(10):\n",
    "        k = 0\n",
    "        for i in range(60000):\n",
    "            if target[i] == j:\n",
    "                spike_trigger_average[j,:] += input[i,:]\n",
    "                k = k+1\n",
    "        spike_trigger_average[j,:] = spike_trigger_average[j,:].cpu()/torch.norm(spike_trigger_average[j,:])\n",
    "        \n",
    "    return spike_trigger_average\n",
    "\n",
    "\n",
    "def generate_correlation_matrix():\n",
    "    '''\n",
    "    Generate spike trigger average of MNIST dataset\n",
    "    (approximated by the mean of each digits in the dataset.)\n",
    "    '''\n",
    "    \n",
    "    train_dataset = torchvision.datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=60000, shuffle=True)\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        a = 0\n",
    "    input = input.reshape(60000,784)\n",
    "\n",
    "    correlated = torch.zeros(10,784,784)\n",
    "\n",
    "    for j in range(10):\n",
    "        for i in range(60000):\n",
    "            if target[i] == j:\n",
    "                correlated[j,:,:] += torch.mm(input[i,:].reshape(784,1),input[i,:].reshape(1,784))\n",
    "        correlated[j,:,:] = correlated[j,:,:]/torch.sum(target==j)\n",
    "        \n",
    "    return correlated\n",
    "\n",
    "\n",
    "def matshow(a):\n",
    "    m = torch.max(abs(a))\n",
    "    plt.figure()    \n",
    "    plt.matshow(a.reshape(28,28),cmap=plt.cm.gray,vmin = -m,vmax = m)\n",
    "    #plt.colorbar()\n",
    "    return\n",
    "\n",
    "\n",
    "def test_matrix(a):\n",
    "    valid_dataset = torchvision.datasets.MNIST(root='data', train=False, transform=transforms.ToTensor())\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=10000)\n",
    "    change_weight(a)\n",
    "    model.eval()\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for i, (input, target) in enumerate(valid_loader):\n",
    "            input, target = input, target.long()\n",
    "                        \n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            valid_total += target.size(0)\n",
    "            valid_correct += (predicted == target).sum().item()\n",
    "\n",
    "            total_loss += loss\n",
    "            \n",
    "            \n",
    "    prec = valid_correct / valid_total\n",
    "    ave_loss = total_loss/len(valid_loader)\n",
    "    print('Accuary on test images:{:.2f}%'.format(prec*100))\n",
    "    return prec\n",
    "\n",
    "\n",
    "def test_eigen(a):\n",
    "    valid_dataset = torchvision.datasets.MNIST(root='data', train=False, transform=transforms.ToTensor())\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=100)\n",
    "    change_eigen(a)\n",
    "    model.eval()\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(valid_loader):\n",
    "            input, target = input.cuda(), target.long().cuda()\n",
    "                        \n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            valid_total += target.size(0)\n",
    "            valid_correct += (predicted == target).sum().item()\n",
    "            \n",
    "    prec = valid_correct / valid_total\n",
    "    print('Accuary on test images:{:.2f}%'.format(prec*100))\n",
    "    return prec\n",
    "\n",
    "\n",
    "def savefig(name):\n",
    "    plt.savefig(name,dpi=600, bbox_inches='tight')\n",
    "    return\n",
    "\n",
    "\n",
    "def generate_adversial_exm_grad(varepsilon):\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=10000)\n",
    "    for i, (input, target) in enumerate(valid_loader):\n",
    "        input, target = input, target.long()\n",
    "        adversial_exm = input\n",
    "        \n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=1)\n",
    "    for i, (input, target) in enumerate(valid_loader):\n",
    "        input, target = input, target.long()\n",
    "\n",
    "        input.requires_grad = True\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "    \n",
    "        adversial_exm[i:i+1,:,:,:] = input + varepsilon*input.grad/torch.norm(input.grad)\n",
    "        \n",
    "        \n",
    "    adversial_exm = adversial_exm.detach()\n",
    "    return adversial_exm.data\n",
    "\n",
    "\n",
    "def generate_adversial_exm_sign(varepsilon):\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=10000)\n",
    "    for i, (input, target) in enumerate(valid_loader):\n",
    "        input, target = input, target.long()\n",
    "        adversial_exm = input\n",
    "        \n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=1)\n",
    "    for i, (input, target) in enumerate(valid_loader):\n",
    "        input, target = input, target.long()\n",
    "\n",
    "        input.requires_grad = True\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "    \n",
    "        adversial_exm[i:i+1,:,:,:] = input + varepsilon*torch.sign(input.grad)\n",
    "        \n",
    "        \n",
    "    adversial_exm = adversial_exm.detach()\n",
    "    return adversial_exm.data\n",
    "\n",
    "def kl_divergence():\n",
    "    number_class = torch.Tensor([0,980,1135,1032,1010,982,892,958,1028,974,1009])\n",
    "    number_class_cor = torch.cumsum(number_class,0)\n",
    "    number_class_mis = torch.cat((torch.zeros(1),torch.cumsum(10000-number_class[1:],0)),0)\n",
    "    all_cos_mistake, all_cos_correct = cos_distribution(new_eigen)\n",
    "    for digit in range(10):\n",
    "        bins=np.arange(0,0.6,0.6/400) # |cos|\n",
    "        bins=np.arange(0,1,1/2000) # cos^2\n",
    "        frequency_each,_,_ = plt.hist(all_cos_mistake[int(number_class_mis[digit]):int(number_class_mis[digit+1])].tolist(), bins = bins,color='blue',label='other label')\n",
    "        frequency_each_c,_,_ = plt.hist(all_cos_correct[int(number_class_cor[digit]):int(number_class_cor[digit+1])].tolist(), color='red', bins = bins,label='true label')\n",
    "        mistaken_dist = frequency_each/(10000-number_class[digit+1])\n",
    "        correct_dist = frequency_each_c/number_class[digit+1]\n",
    "        mistaken_dist[mistaken_dist == 0] = 1e-16*torch.ones((mistaken_dist == 0).sum()).double()\n",
    "        correct_dist[correct_dist == 0] = 1e-16*torch.ones((correct_dist == 0).sum()).double()\n",
    "        KL_divergence = F.kl_div(mistaken_dist.log(),correct_dist , None, None, 'sum')\n",
    "        KL_divergence_1 = F.kl_div(correct_dist.log(),mistaken_dist , None, None, 'sum')\n",
    "        KL_div.append(KL_divergence)\n",
    "        KL_div_1.append(KL_divergence_1) \n",
    "    return\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    #torch.backends.cudnn.benchmark = True #for accelerating the running\n",
    "    return\n",
    "\n",
    "def ks():\n",
    "    input_digit = input[target==digit,:,:,:] \n",
    "    output = model(input_digit)\n",
    "\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    valid_total = output.shape[0]\n",
    "    valid_correct = (predicted == digit).sum().item()\n",
    "    all_cos_cor = torch.zeros(output.shape[0])\n",
    "    all_cos_mis = torch.zeros(9,output.shape[0])    \n",
    "\n",
    "    for index in range(output.shape[0]):\n",
    "        output[index,:] = output[index,:]/torch.norm(input_digit[index,:],2)\n",
    "        all_cos_cor[index] = output[index, digit]\n",
    "        all_cos_mis[:,index] = output[index, torch.arange(10).cuda() != digit]\n",
    "\n",
    "\n",
    "    bins=np.arange(0,1.001,1/2000) \n",
    "    frequency_each,_ = np.histogram(all_cos_mis.reshape(9*output.shape[0]).tolist(), bins = bins)\n",
    "    frequency_each_c,_ = np.histogram(all_cos_cor.tolist(), bins = bins)\n",
    "    cdf_mistaken = torch.cat((torch.Tensor([0]),torch.cumsum(torch.from_numpy(frequency_each)/(9*output.shape[0]), dim=0)),0)\n",
    "    cdf_correct = torch.cat((torch.Tensor([0]),torch.cumsum(torch.from_numpy(frequency_each_c)/output.shape[0], dim=0)),0)\n",
    "    KS_distance = torch.max(abs(cdf_correct-cdf_mistaken))\n",
    "    KS_dis.append(KS_distance) \n",
    "    return\n",
    "\n",
    "#ax1.spines['top'].set_visible(False)\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Process"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "setup_seed(1)\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "valid_dataset = torchvision.datasets.MNIST(root='data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "#FMNIST dataset\n",
    "#train_dataset = torchvision.datasets.FashionMNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "#valid_dataset = torchvision.datasets.FashionMNIST(root='data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=10000)\n",
    "all_train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=60000, shuffle=False)\n",
    "\n",
    "#num_eigen = 2\n",
    "#initial_number = 4\n",
    "#EI_distribution = torch.bernoulli(torch.ones(784)*0.75)\n",
    "#torch.save(EI_distribution,'EI_distribution')\n",
    "#print('number of excitatory neuron:{}'.format(EI_distribution.sum()))\n",
    "#kappa_matrix = -torch.ones(784, 784)\n",
    "#kappa_matrix[EI_distribution==0,:] = 1\n",
    "#kappa_matrix[:,EI_distribution==0] = 1\n",
    "model = simplenet.SimpleNet_1(num_eigens=1)\n",
    "eigen = model.state_dict()['classifier.0.eigen']\n",
    "theta_0_norm = torch.norm(eigen)\n",
    "with torch.no_grad():\n",
    "    for j, (input, target) in enumerate(all_train_loader):\n",
    "        input, target = input, target.long()\n",
    "        output = model(input)\n",
    "    output_theta0_norm = torch.norm(output,dim=1)\n",
    "#model = nn.DataParallel(model, device_ids=[0]).cuda()\n",
    "#model = twolayernet.TwoLayerNet_0(num_eigens = num_eigen, hidden_layers_neuron = hidden_layer_neuron)\n",
    "#model = nn.DataParallel(model, device_ids=[0]).cuda()\n",
    "#model = nn.DataParallel(model, device_ids=[0])\n",
    "print(model)\n",
    "#initial_weight_a = model.state_dict()['classifier.0.weight_a']\n",
    "#torch.save(initial_weight_a,'initial_weight_a')\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "test_accuracy = []\n",
    "KS_dis = []\n",
    "train_accuracy = [0]  \n",
    "all_train_loss = []\n",
    "image_list = []\n",
    "monotone = []\n",
    "norm = []\n",
    "output_std_true = []\n",
    "output_std_other = []\n",
    "output_norm = []\n",
    "mean = []\n",
    "gamma_t = []\n",
    "u1u2_innerpro = []\n",
    "u1u3_innerpro = []\n",
    "alpha1_all = []\n",
    "alpha2_all = []\n",
    "alpha3_all = []\n",
    "all_partial_snj_norm = []\n",
    "all_dtheta_norm = []\n",
    "\n",
    "#new_weight = torch.zeros(10,784,784)\n",
    "number = 0\n",
    "best_prec = 0\n",
    "min_loss = 1\n",
    "a = 1/torch.Tensor(torch.load('a_randomseed_1_norm_square'))\n",
    "#b = torch.load('b')\n",
    "#eigen = model.state_dict()['classifier.0.eigen']\n",
    "#new_eigen[:,:,:initial_number] = torch.load('{}_rank_after_train'.format(initial_number))\n",
    "#new_eigen[:,:,initial_number:] = eigen[:,:,initial_number:]*10\n",
    "#change_eigen(new_eigen)\n",
    "\n",
    "#change initial value\n",
    "#for i in range(10):\n",
    " #   weight_a[i+1,:,:] = correlated[i+1,:,:]\n",
    " #   correlated_change[i,:,:] = correlated[9,:,:]\n",
    "#change_weight(torch.load('first_five_eig'))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    #elif epoch < 10:\n",
    "     #   lr = 0.001\n",
    "    #else:\n",
    "     #   lr = 0.0001\n",
    "\n",
    "    \n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = 0.01\n",
    "\n",
    "    model.train()\n",
    "    # train for one epoch\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        train_total = 0\n",
    "        train_correct = 0\n",
    "        train_loss = 0\n",
    "        # measure data loading time\n",
    "        input, target = input, target.long()\n",
    "                    \n",
    "        \n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        #weight_a = model.state_dict()['classifier.0.weight_a']\n",
    "        #new_weight = weight_a.data\n",
    "        #for j in range(10):\n",
    "         #   new_weight[j,(new_weight[j,:,:]*kappa_matrix)<0] = 0\n",
    "\n",
    "        #change_weight(new_weight)  \n",
    "\n",
    "        # for name, parms in model.named_parameters():\n",
    "        #     print('-->name:', name, '-->grad_requirs:',parms.requires_grad, '-->grad_value:',parms.grad)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        train_total += target.size(0)\n",
    "        train_correct += (predicted == target).sum().item()\n",
    "        prec = train_correct / train_total\n",
    "\n",
    "        #eigen = model.state_dict()['classifier.0.eigen']\n",
    "        #for j in range(10):\n",
    "         #   new_eigen[j,:,:] = eigen[j,:,:]/torch.norm(eigen[j,:,:],'fro')\n",
    "        #change_eigen(new_eigen)\n",
    "\n",
    "        #weight_a = model.state_dict()['classifier.0.weight_a']\n",
    "        #for j in range(10):\n",
    "         #   new_weight[j,:,:] = weight_a[j,:,:]/torch.norm(weight_a[j,:,:],'fro')\n",
    "        #change_weight(new_weight)\n",
    "\n",
    "        if i < 300:\n",
    "            if (i) % 2 == 0:\n",
    "                train_accuracy.append(prec)\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.5f}, Train_Acc:{:.2f}%'.format(epoch+1, 20, i, len(train_loader), loss, prec*100))\n",
    "\n",
    "                \n",
    "        # evaluate on test set\n",
    "        # switch to evaluate mode\n",
    "        \n",
    "                model.eval()\n",
    "                valid_correct = 0\n",
    "                valid_total = 0\n",
    "                with torch.no_grad():\n",
    "                    total_loss = 0\n",
    "                    for j, (input, target) in enumerate(valid_loader):\n",
    "                        input, target = input, target.long()\n",
    "                        output = model(input)\n",
    "\n",
    "\n",
    "                        \n",
    "                        _, predicted = torch.max(output.data, 1)\n",
    "                        valid_total = output.shape[0]\n",
    "                        valid_correct = (predicted == target).sum().item()\n",
    "                        loss = criterion(output, target)\n",
    "\n",
    "                        #for digit in range(10):\n",
    "                        #   for index in range(output.shape[0]):\n",
    "                        #      if target[index] == digit:\n",
    "                        #         out[number,:,digit] += output[index,:]/((torch.norm(eigen[digit,:,:],2)*torch.norm(output_first_layer_after[index,:],2))**2)\n",
    "                            #out[number,:,digit] = torch.mean(output[target==digit,:],dim=0)\n",
    "                        #number += 1\n",
    "\n",
    "                        prec = valid_correct / valid_total\n",
    "                        print('Accuary on test images:{:.2f}%, loss:{:.5f}'.format(prec*100, loss))\n",
    "                        test_accuracy.append(prec)\n",
    "                        #all_train_loss.append(loss)\n",
    "                        best_prec = max(prec, best_prec)\n",
    "\n",
    "\n",
    "                model.train()    \n",
    "                for j, (input, target) in enumerate(all_train_loader):\n",
    "                    input, target = input, target.long()\n",
    "                    output = model(input)\n",
    "\n",
    "                    output_norm.append(torch.norm(output,dim=1).data)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "\n",
    "                    eigen = model.state_dict()['classifier.0.eigen']\n",
    "                    norm.append(torch.norm(eigen))\n",
    "\n",
    "                    for name, param in model.named_parameters():\n",
    "                        dtheta = -param.grad.data.clone()\n",
    "\n",
    "\n",
    "                    all_dtheta_norm.append(torch.norm(dtheta))\n",
    "                    dtheta = dtheta/torch.norm(dtheta)\n",
    "\n",
    "                    alpha_1 = torch.sum(dtheta*eigen)/torch.norm(eigen)\n",
    "\n",
    "                    alpha1_all.append(alpha_1)\n",
    "                    u1 = dtheta-alpha_1*eigen/torch.norm(eigen)\n",
    "\n",
    "                    partial_snj = torch.zeros(10,784,1)\n",
    "                    #partial_snj_1 = torch.zeros(10,784,1)\n",
    "                    for n in range(60000):\n",
    "                        for j in torch.arange(10):\n",
    "                      #      if j != target[n]:\n",
    "                                #model.zero_grad()\n",
    "                                #output = model(input)\n",
    "                                #snj = output[n,target[n]]-output[n,j]\n",
    "                                #snj.backward()\n",
    "                                #for name, param in model.named_parameters():\n",
    "                               #     partial_snj += param.grad.data.clone()*a[n]\n",
    "\n",
    "                                partial_snj[j,:,0] += -a[n]*2*torch.sum(eigen[j,:,0]*input[n,0,:,:].reshape(784))*input[n,0,:,:].reshape(784)\n",
    "                      #          partial_snj_1[j,:,0] += -b[n]*2*torch.sum(eigen[j,:,0]*input[n,0,:,:].reshape(784))*input[n,0,:,:].reshape(784)\n",
    "                        partial_snj[target[n],:,0] += a[n]*18*torch.sum(eigen[target[n],:,0]*input[n,0,:,:].reshape(784))*input[n,0,:,:].reshape(784)\n",
    "                     #   partial_snj_1[target[n],:,0] += b[n]*18*torch.sum(eigen[target[n],:,0]*input[n,0,:,:].reshape(784))*input[n,0,:,:].reshape(784)\n",
    "                    partial_snj_norm = torch.norm(partial_snj)\n",
    "                    all_partial_snj_norm.append(partial_snj_norm)\n",
    "                    partial_snj = partial_snj/partial_snj_norm\n",
    "                    #partial_snj_1 = partial_snj_1/partial_snj_norm\n",
    "                    \n",
    "                    alpha_2 = torch.sum(partial_snj*eigen)/torch.norm(eigen)\n",
    "                    alpha2_all.append(alpha_2)\n",
    "\n",
    "                    #alpha_3 = torch.sum(partial_snj_1*eigen)/torch.norm(eigen)\n",
    "                    #alpha3_all.append(alpha_3)\n",
    "\n",
    "                    u2 = partial_snj-alpha_2*eigen/torch.norm(eigen)\n",
    "                    u1u2_innerpro.append(torch.sum(u1*u2))\n",
    "\n",
    "                    #u3 = partial_snj_1-alpha_3*eigen/torch.norm(eigen)\n",
    "                    #u1u3_innerpro.append(torch.sum(u1*u3))\n",
    "\n",
    "                    gamma_t.append((torch.norm(eigen)**2-theta_0_norm**2)/(torch.norm(eigen)**2))\n",
    "\n",
    "                    #with torch.no_grad():\n",
    "                     #   all_cos_cor = torch.zeros(output.shape[0])\n",
    "                      #  all_cos_mis = torch.zeros(9,output.shape[0])  \n",
    "                       # mean_difference = 0\n",
    "                        #for index in range(output.shape[0]):\n",
    "                         #   output[index,:] = output[index,:]/torch.norm(output[index,:],2)\n",
    "                          #  all_cos_cor[index] = output[index, target[index]]\n",
    "                           # all_cos_mis[:,index] = output[index, torch.arange(10) != target[index]]\n",
    "                            #for digit in range(10):\n",
    "                             #   if digit != target[index]:\n",
    "                              #      mean_difference += output[index, target[index]]-output[index,digit]\n",
    "\n",
    "                       # mean.append(mean_difference/540000)\n",
    "\n",
    "                            #output_std_other.append(torch.std(all_cos_mis, unbiased=True))\n",
    "                            #output_std_true.append(torch.std(all_cos_cor, unbiased=True))\n",
    "                            #print(torch.std(all_cos_cor, unbiased=True), torch.std(all_cos_mis, unbiased=True))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        #bins=np.arange(min(torch.min(all_cos_cor), torch.min(all_cos_mis)),max(torch.max(all_cos_cor), torch.max(all_cos_mis)), 1/2000) \n",
    "                        #frequency_each,_ = np.histogram(all_cos_mis.reshape(9*output.shape[0]).tolist(), bins = bins)\n",
    "                        #frequency_each_c,_ = np.histogram(all_cos_cor.tolist(),bins = bins)\n",
    "                        #cdf_mistaken = torch.cat((torch.Tensor([0]),torch.cumsum(torch.from_numpy(frequency_each)/(9*output.shape[0]), dim=0)),0)\n",
    "                        #cdf_correct = torch.cat((torch.Tensor([0]),torch.cumsum(torch.from_numpy(frequency_each_c)/output.shape[0], dim=0)),0)\n",
    "                        #KS_distance = torch.max(abs(cdf_correct-cdf_mistaken))\n",
    "                        #KS_dis.append(KS_distance)\n",
    "\n",
    "print('Best accuracy is: {:.2f}%, Minimum loss is: {:.4f}'.format(best_prec*100, min_loss))\n",
    "#weight_a = model.state_dict()['classifier.0.weight_a']\n",
    "#torch.save(weight_a,'after_train_weight')\n",
    "#torch.save(weight_a,'weight_a')\n",
    "#eigen = model.state_dict()['classifier.0.eigen']\n",
    "#torch.save(eigen,'eigen_9')\n",
    "\n",
    "#imageio.mimsave('distribution_of_cos.gif', image_list, duration=0.2) \n",
    "#spike_trigger_average = generate_spike_trigger_average()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ft = (torch.Tensor(gamma_t))*torch.Tensor(u1u2_innerpro)+torch.Tensor(alpha1_all)*torch.Tensor(alpha2_all)*(torch.Tensor(gamma_t)-0.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#rhs = 1/(2*(torch.Tensor(u1u2_innerpro)/(torch.Tensor(alpha1_all)*torch.Tensor(alpha2_all))+1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig,ax = plt.subplots(1,1, layout=\"constrained\", figsize=(5,4))\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.plot(2*(torch.arange(80)+20), torch.zeros(80), linestyle='--', linewidth=2, color = 'black')\n",
    "plt.plot(2*(torch.arange(80)+20), test_diff[19:99], linestyle='--', linewidth=2, color = 'gray', label='Accuracy\\ndifference')\n",
    "plt.scatter(2*(torch.arange(80)+20),ft[20:100],c = test_accuracy[20:100],cmap=plt.cm.rainbow,s=5)\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('test accuracy',fontsize=12)\n",
    "plt.xlabel(r'Training steps')\n",
    "plt.ylabel(r'$\\frac{d}{dt}(\\mu_1-\\mu_2)$')\n",
    "plt.legend(loc='best')\n",
    "savefig('test_difference.pdf')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#output_std_true = torch.log(torch.Tensor(output_std_true))\n",
    "#norm = torch.log(torch.Tensor(norm)-1)\n",
    "a = []\n",
    "#output_norm = torch.stack(output_norm)\n",
    "for i in range(60000):\n",
    "    end = 75\n",
    "    output_std_true = (torch.Tensor(norm)**2)[:end]\n",
    "    output_std_other = output_norm[:end,i].data\n",
    "\n",
    "    A = torch.cat(((torch.Tensor(output_std_true)).unsqueeze(0),torch.ones(len(output_std_true)).unsqueeze(0)), dim=0)\n",
    "    B = torch.Tensor(output_std_other).unsqueeze(0)\n",
    "    x = torch.linalg.lstsq(A.T, B.T).solution\n",
    "    r_square = 1 - torch.sum((B.squeeze(0)-torch.mm(A.T, x).squeeze(1))**2)/torch.sum((B.squeeze(0)-torch.mean(B.squeeze(0)))**2)\n",
    "    print(r_square)\n",
    "    a.append(x[0][0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig,ax = plt.subplots(1,1, layout=\"constrained\", figsize=(5,4))\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "#torch.mm(A.T, x).squeeze(0)\n",
    "#c=test_accuracy\n",
    "plt.plot(torch.Tensor(output_std_true), torch.mm(A.T, x).squeeze(0), linestyle='--', linewidth=2, label='$r^2 = {:.2f}$'.format(r_square), color = 'black')\n",
    "plt.scatter(torch.Tensor(output_std_true), output_std_other,c = test_accuracy[:end], cmap=plt.cm.rainbow,s=5)\n",
    "#plt.xlabel(r'$||x_n||_2^2$')\n",
    "#plt.ylabel(r'$a_n $')\n",
    "plt.title(r'$||\\Phi(x_5,\\theta)||_2  = {:.2f}||\\theta||_2^2  {:.2f}$'.format(x[0][0],x[1][0]))\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('test accuracy',fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "#savefig('mnist_5_outputnorm_vs_norm.pdf')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_diff = torch.diff(test_accuracy)\n",
    "plt.plot(test_diff)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# plot KS distance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_accuracy = torch.Tensor(test_accuracy)\n",
    "KS_dis = torch.Tensor(KS_dis)\n",
    "mean = torch.Tensor(mean)\n",
    "to = 150\n",
    "begin = 0\n",
    "#for digit in range(10):\n",
    "\n",
    "plt.figure(figsize=(4,4)) \n",
    "ax1 = plt.subplot(111)\n",
    "\n",
    "plt.xticks(weight = 'bold')\n",
    "ax1.plot(2*torch.arange(len(test_accuracy))[begin:to] ,test_accuracy[begin:to] ,color = 'blue',linewidth = 3)\n",
    "plt.yticks(weight = 'bold')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(2*torch.arange(len(test_accuracy))[begin:to], mean[begin:to] ,color = 'red',linewidth = 2,linestyle = '--')\n",
    "ax1.set_xlabel(\"Training steps\",fontsize = 12, fontweight = 'bold')\n",
    "ax2.set_ylabel('$\\mu_1-\\mu_2$',fontsize = 12, color = 'red', fontweight = 'bold')\n",
    "ax1.set_ylabel('Test accuracy',fontsize = 12, color = 'blue', fontweight = 'bold')\n",
    "plt.yticks(weight = 'bold')\n",
    "plt.title('LR-NN: MNIST', fontsize = 12, fontweight = 'bold')\n",
    "ax1.grid()\n",
    "#ax2.set_ylim([-0.025,0.5])\n",
    "\n",
    "#plt.title('Digit {}'.format(digit), fontsize = 20)\n",
    "#savefig('20-150-md_mnist.pdf')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Distribution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "plt.figure()\n",
    "plt.plot(bins, cdf_correct, color = 'lime', linewidth=4, linestyle='--',label='True label cdf')\n",
    "plt.plot(bins, cdf_mistaken, color = 'aqua', linewidth=4, linestyle='--',label='Other label cdf')\n",
    "plt.xlabel('Output under L2 normalization',fontsize=20)\n",
    "plt.ylabel('Cumulative probability',fontsize = 20)\n",
    "plt.title('KS distance = {:.2f}'.format(KS_distance))\n",
    "plt.legend(fontsize=15,loc= 'lower right')\n",
    "savefig('temp.png')\n",
    "plt.show()\n",
    "image_list.append(imageio.imread('temp.png'))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Confusion matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=10000)\n",
    "change_eigen(spike_trigger_average.reshape(10,784,1))\n",
    "for wo, (input, target) in enumerate(valid_loader):\n",
    "    input, target = input.cuda(), target.cuda()\n",
    "output = model(input)\n",
    "_, predicted = torch.max(output.data, 1)\n",
    "number = torch.Tensor([980,1135,1032,1010,982,892,958,1028,974,1009])\n",
    "confusion_matrix = torch.zeros(10,10)\n",
    "for i in range(10000):\n",
    "    confusion_matrix[target[i], predicted[i]] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    confusion_matrix[i,:] = confusion_matrix[i,:]/number[i]\n",
    "confusion_matrix = confusion_matrix.numpy()\n",
    "confusion_matrix = np.around(confusion_matrix,3)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=plt.cm.GnBu,annot_kws={'size':7,'weight':'bold'})\n",
    "plt.xlabel('Predict label', fontsize = 20)\n",
    "plt.ylabel('True label', fontsize = 20)\n",
    "savefig('spike_confusion_matrix.svg')\n",
    "plt.show()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adversial Examples and Gaussion noise"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for j, (input, target) in enumerate(valid_loader):\n",
    "    input, target = input, target.long()\n",
    "\n",
    "test_accuracy = torch.zeros(10)\n",
    "adversial_input_all = torch.zeros(10,10000,784)\n",
    "for j in range(10):\n",
    "    varepsilon = 0.01*j\n",
    "    #adversial_input = generate_adversial_exm_grad(varepsilon)\n",
    "    adversial_input_1 = generate_adversial_exm_sign(varepsilon)\n",
    "    adversial_input_all[j,:,:] = adversial_input_1.reshape(10000,784)\n",
    "\n",
    "    model.eval()\n",
    "#valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=10000)\n",
    "#for i, input in enumerate(valid_loader):\n",
    " #   input = input\n",
    "\n",
    "#valid_correct = 0\n",
    "#valid_total = 0\n",
    "#with torch.no_grad():\n",
    " #   output = model(adversial_input)\n",
    "\n",
    "   # _, predicted = torch.max(output.data, 1)\n",
    "    #valid_total = target.size(0)\n",
    "    #valid_correct = (predicted == target).sum().item()\n",
    "\n",
    "\n",
    "\n",
    "#prec = valid_correct / valid_total\n",
    "#print('Accuary on test images:{:.2f}%, epsilon:{}'.format(prec*100, j*0.1))\n",
    "\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    with torch.no_grad():\n",
    "        output = model(adversial_input_1)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        valid_total = target.size(0)\n",
    "        valid_correct = (predicted == target).sum().item()\n",
    "\n",
    "\n",
    "    prec_1 = valid_correct / valid_total\n",
    "    print('Accuary on test images:{:.2f}%, epsilon:{}'.format(prec_1*100, varepsilon))\n",
    "\n",
    "#input = input.reshape(10000,512)\n",
    "#difference = torch.cat([difference,torch.zeros(10000,1)],dim=1)\n",
    "    test_accuracy[j] = prec_1 #gradient ad\n",
    "#test_accuracy[1,j] = prec_1 #sign ad"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for j, (input, target) in enumerate(valid_loader):\n",
    "    input, target = input, target.long()\n",
    "\n",
    "test_accuracy = torch.zeros(10)\n",
    "for j in range(10):\n",
    "#adversial_input = generate_adversial_exm_grad(0.5)\n",
    "    adversial_input_1 = torch.load('ad_all_mnist_sign')[j,:,:]\n",
    "\n",
    "    model.eval()\n",
    "#valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=10000)\n",
    "#for i, input in enumerate(valid_loader):\n",
    " #   input = input\n",
    "\n",
    "#valid_correct = 0\n",
    "#valid_total = 0\n",
    "#with torch.no_grad():\n",
    " #   output = model(adversial_input)\n",
    "\n",
    "   # _, predicted = torch.max(output.data, 1)\n",
    "    #valid_total = target.size(0)\n",
    "    #valid_correct = (predicted == target).sum().item()\n",
    "\n",
    "\n",
    "\n",
    "#prec = valid_correct / valid_total \n",
    "#print('Accuary on test images:{:.2f}%, epsilon:{}'.format(prec*100, j*0.1))\n",
    "\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    with torch.no_grad():\n",
    "        output = model(adversial_input_1)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        valid_total = target.size(0)\n",
    "        valid_correct = (predicted == target).sum().item()\n",
    "\n",
    "\n",
    "    prec_1 = valid_correct / valid_total\n",
    "    print('Accuary on test images:{:.2f}%, epsilon:{}'.format(prec_1*100, j*0.01))\n",
    "    test_accuracy[j] = prec_1\n",
    "\n",
    "torch.save(test_accuracy, 'ad_sign_quadratic_mnist')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i, (input, target) in enumerate(valid_loader):\n",
    "    input, target = input.reshape(10000,784), target.long()\n",
    "\n",
    "weight = model.state_dict()['classifier.0.weight']\n",
    "bias = model.state_dict()['classifier.0.bias']\n",
    "weight_all = torch.cat([weight,bias.reshape(10,1)],dim=1).cpu()\n",
    "feature_map_all = torch.cat([input,torch.ones(10000,1)],dim=1).cpu()\n",
    "\n",
    "Sigma = torch.mm((feature_map_all-torch.mean(feature_map_all,dim=0)).T, feature_map_all-torch.mean(feature_map_all,dim=0))/10000\n",
    "Sigma = Sigma+0.001*torch.mean(abs(Sigma))*torch.diag(torch.ones(785))\n",
    "u,s,v = torch.svd(Sigma)\n",
    "\n",
    "def f(x,w):\n",
    "    mu = 2*torch.mm(torch.mm(w.T,Sigma),x)/(torch.norm(w)**2)\n",
    "    lambda1 = torch.mm(torch.mm(x.T,Sigma),x)\n",
    "    y = -2*torch.mm(Sigma,x)+mu*w+2*lambda1*x\n",
    "    return y\n",
    "\n",
    "def Jf(x,w):\n",
    "    lambda1 = torch.mm(torch.mm(x.T,Sigma),x)\n",
    "    J = -2*Sigma+2*torch.mm(torch.mm(w,w.T),Sigma)/(torch.norm(w)**2)+4*torch.mm(torch.mm(x,x.T),Sigma)+2*lambda1*torch.diag(torch.ones(785))\n",
    "    return J\n",
    "\n",
    "\n",
    "digit = 7\n",
    "\n",
    "w = weight_all[digit:digit+1,:].T\n",
    "x = w/(torch.norm(w)**2)\n",
    "for steps in range(25):\n",
    "    delta_x = -torch.mm(torch.inverse(Jf(x,w)),f(x,w))\n",
    "    x = x + delta_x\n",
    "print(torch.norm(x),torch.mm(x.T,w),torch.norm(f(x,w)))\n",
    "print(torch.mm(torch.mm(x.T,Sigma),x), s[0:30], torch.mm(torch.mm(w.T,Sigma),w)/(torch.norm(w)**2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "project_vector = torch.cat([w,x],dim=1)\n",
    "\n",
    "\n",
    "low_dimension_data = torch.matmul(feature_map_all,project_vector)\n",
    "plt.figure(figsize=(4,4))\n",
    "ax = plt.subplot()\n",
    "for classes in range(10):\n",
    "    ax.scatter(low_dimension_data[target==classes,0], low_dimension_data[target==classes,1],label='{}'.format(classes), s=1)\n",
    "ax.set_xlabel('$w_{}$'.format(digit),fontsize=12)\n",
    "ax.set_ylabel('pc $\\perp \\ w_{}$ '.format(digit),fontsize=12)\n",
    "#ax.legend(bbox_to_anchor=(1,1),fontsize=12, markerscale=8)\n",
    "#ax.set_title('Class {}'.format(digit),fontsize=14)\n",
    "savefig('dim_redu_mnist_{}.png'.format(digit))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make the input close to the network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "spike_trigger_average = generate_spike_trigger_average()\n",
    "change_eigen(spike_trigger_average.reshape(10,784,1))\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=10000)\n",
    "for i, (input, target) in enumerate(valid_loader):\n",
    "    input, target = input.cuda(), target.cuda()\n",
    "    ad_exm = input\n",
    "    ad_exm.requires_grad = True\n",
    "    \n",
    "for epoch in range(20):\n",
    "    for i in range(10000):\n",
    "        a = ad_exm[i:i+1,:,:,:]\n",
    "        a.retain_grad()\n",
    "        \n",
    "        output = model(a)\n",
    "        loss = criterion(output, target[i:i+1])\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ad_exm[i:i+1,:,:,:] = a - 0.2*a.grad/torch.norm(a.grad)\n",
    "        \n",
    "        \n",
    "    model.eval()\n",
    "        \n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    with torch.no_grad():\n",
    "        output = model(ad_exm)\n",
    "\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        valid_total += target.size(0)\n",
    "        valid_correct += (predicted == target).sum().item()\n",
    "\n",
    "\n",
    "\n",
    "    prec = valid_correct / valid_total\n",
    "    print('Accuary on test images:{:.2f}%'.format(prec*100))\n",
    "    print(epoch)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis of one-rank network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## 动力学\n",
    "#image_list = []\n",
    "#for i in range(600):\n",
    " #   a = torch.zeros(784)\n",
    "  #  for j in range(784):\n",
    "   #     a[j] = max(abs(weight_we_need[i,j,:]))\n",
    "    #plt.matshow(a.reshape(28,28),cmap = plt.cm.Blues)\n",
    "    #plt.savefig('temp.png')\n",
    "    #image_list.append(imageio.imread('temp.png'))\n",
    "#imageio.mimsave('pic6.gif', image_list, duration=0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 比较线性与非线性的贡献\n",
    "#train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=60000, shuffle=True)\n",
    "#for i, (input, target) in enumerate(train_loader):\n",
    " #   a = 1\n",
    "    \n",
    "#output = model(input)\n",
    "#linear_term = []\n",
    "#bilinear_term = []\n",
    "#for i in range(60000):\n",
    " #   category = output[i,:].argmax().cpu()\n",
    "   # if category == 1:\n",
    "  #  weight_bilinear = weight_a[category,:,:].cpu()\n",
    "   # weight_linear = weight_b[category,:].reshape(1,784).cpu()\n",
    "    #input_now = input[i,0,:,:].reshape(784,1).cpu()\n",
    "    #linear_term.append(torch.mm(weight_linear, input_now)*5) \n",
    "    #bilinear_term.append(torch.mm(torch.mm(input_now.t(), weight_bilinear),input_now))\n",
    "    #if i % 1000 == 0:\n",
    "     #   print(i)\n",
    "\n",
    "#fig = plt.figure() \n",
    "#ax1 = fig.add_subplot(111)\n",
    "\n",
    "#ax1.bar(torch.arange(len(bilinear_term)), bilinear_term, color = 'r',width = 1,alpha = 0.7,label = 'bilinear term')\n",
    "#ax1.bar(torch.arange(len(linear_term)), linear_term,color = 'b',width = 1 , label = 'linear term')\n",
    "#ax1.set_xlabel('Picture index',fontsize = 20)\n",
    "#ax1.set_ylabel('Magnitude after NN',fontsize = 20)\n",
    "#ax1.legend(fontsize = '15', loc = 'best')\n",
    "#ax1.set_ylim(-1, 40)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.9 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "4dc8b9ca2dd743165c9a23c64ed5faa802a7566e9a05ea7fbc4e7eac82525774"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}